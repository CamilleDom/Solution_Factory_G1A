{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4a7125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed thresholds and stats from labeled examples:\n",
      "- brightness: threshold = 116.02, std = 12.45, direction: clean\n",
      "- file_size_kb: threshold = 441.76, std = 1122.96, direction: dirty\n",
      "- contrast: threshold = 245.73, std = 8.42, direction: clean\n",
      "- sobel_edge_count: threshold = 8520.83, std = 1877.68, direction: dirty\n",
      "- center_edge_count: threshold = 907.80, std = 239.98, direction: clean\n",
      "- surround_edge_count: threshold = 2193.93, std = 699.16, direction: dirty\n",
      "\n",
      "Enhanced rule-based classifier accuracy on first 40 labeled images: 75.00%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16  4  0]\n",
      " [ 6 14  0]\n",
      " [ 0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean       0.73      0.80      0.76        20\n",
      "       dirty       0.78      0.70      0.74        20\n",
      "\n",
      "    accuracy                           0.75        40\n",
      "   macro avg       0.75      0.75      0.75        40\n",
      "weighted avg       0.75      0.75      0.75        40\n",
      "\n",
      "\n",
      "Enhanced classification complete. Results saved in 'features_with_enhanced_pattern_labels.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ---------------------------\n",
    "# Data Loading & Preprocessing\n",
    "# ---------------------------\n",
    "# Load your CSV file which contains the extracted features:\n",
    "# avg_r, avg_g, avg_b, file_size_kb, contrast, sobel_edge_count, center_edge_count, surround_edge_count\n",
    "df = pd.read_csv(\"features.csv\")\n",
    "\n",
    "# Create a derived feature for overall brightness.\n",
    "df['brightness'] = (df['avg_r'] + df['avg_g'] + df['avg_b']) / 3\n",
    "\n",
    "# Manually assign ground truth for the first 40 images:\n",
    "# Rows 0-19 are 'clean' and rows 20-39 are 'dirty'\n",
    "df.loc[:19, 'true_label'] = 'clean'\n",
    "df.loc[20:39, 'true_label'] = 'dirty'\n",
    "\n",
    "# ---------------------------\n",
    "# Derive Thresholds & Normalization Stats from Labeled Data\n",
    "# ---------------------------\n",
    "# Choose the features we want to use.\n",
    "feature_cols = [\n",
    "    'brightness',\n",
    "    'file_size_kb',\n",
    "    'contrast',\n",
    "    'sobel_edge_count',\n",
    "    'center_edge_count',\n",
    "    'surround_edge_count'\n",
    "]\n",
    "\n",
    "# For each feature, compute:\n",
    "#   - The midpoint threshold between clean and dirty (using the first 40 examples)\n",
    "#   - The standard deviation (over those 40 examples) for normalization.\n",
    "#   - The “direction” of the feature: if clean images have a higher mean value than dirty images,\n",
    "#     then a higher value votes for clean. Otherwise, a higher value votes for dirty.\n",
    "stats = {}  # Dictionary: key = feature name; value = dict with threshold, std, direction.\n",
    "labeled = df.loc[:39].copy()\n",
    "print(\"Computed thresholds and stats from labeled examples:\")\n",
    "for feature in feature_cols:\n",
    "    mean_clean = labeled[labeled['true_label'] == 'clean'][feature].mean()\n",
    "    mean_dirty = labeled[labeled['true_label'] == 'dirty'][feature].mean()\n",
    "    threshold = (mean_clean + mean_dirty) / 2.0\n",
    "    std_f = labeled[feature].std(ddof=0)  # Population standard deviation\n",
    "    # Determine the direction. If the average for 'clean' images is higher than 'dirty',\n",
    "    # then a high value is evidence for clean, otherwise for dirty.\n",
    "    if mean_clean > mean_dirty:\n",
    "        direction = 'clean'\n",
    "    else:\n",
    "        direction = 'dirty'\n",
    "    stats[feature] = {\n",
    "         'threshold': threshold,\n",
    "         'std': std_f,\n",
    "         'direction': direction,\n",
    "         'mean_clean': mean_clean,\n",
    "         'mean_dirty': mean_dirty,\n",
    "    }\n",
    "    print(f\"- {feature}: threshold = {threshold:.2f}, std = {std_f:.2f}, direction: {direction}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Enhanced Rule-Based Classification Using Weighted Z-Scores\n",
    "# ---------------------------\n",
    "def classify_image_z(row, stats, delta=0.0):\n",
    "    \"\"\"\n",
    "    For each image, compute the normalized (z-score) difference from the threshold for each feature.\n",
    "    If a feature is such that higher values indicate 'dirty', we reverse the z-score so that in all\n",
    "    cases a positive contribution indicates evidence for 'clean' and a negative contribution indicates 'dirty'.\n",
    "    \n",
    "    The final score is the sum of contributions from all features.\n",
    "      - If the total score > delta, label as 'clean'.\n",
    "      - If the total score < -delta, label as 'dirty'.\n",
    "      - Otherwise, label as 'uncertain'.\n",
    "    \"\"\"\n",
    "    total_score = 0.0\n",
    "    for feature in feature_cols:\n",
    "        threshold = stats[feature]['threshold']\n",
    "        std_f = stats[feature]['std']\n",
    "        # Avoid division by zero. If std is zero, treat z as zero.\n",
    "        if std_f == 0:\n",
    "            z = 0.0\n",
    "        else:\n",
    "            z = (row[feature] - threshold) / std_f\n",
    "        # If higher values favor dirty, reverse the sign.\n",
    "        if stats[feature]['direction'] == 'dirty':\n",
    "            total_score -= z\n",
    "        else:\n",
    "            total_score += z\n",
    "    # Decision based on the summed score.\n",
    "    if total_score > delta:\n",
    "        return 'clean'\n",
    "    elif total_score < -delta:\n",
    "        return 'dirty'\n",
    "    else:\n",
    "        return 'uncertain'\n",
    "\n",
    "# ---------------------------\n",
    "# Apply the Enhanced Classifier & Evaluate\n",
    "# ---------------------------\n",
    "# Use the new classification function.\n",
    "# You can adjust delta (a minimal margin) if you wish to favor 'uncertain' in borderline cases.\n",
    "df['auto_label'] = df.apply(lambda row: classify_image_z(row, stats, delta=0.0), axis=1)\n",
    "\n",
    "# Evaluate performance on the first 40 labeled images.\n",
    "df_eval = df.loc[:39]\n",
    "correct_predictions = (df_eval['auto_label'] == df_eval['true_label']).sum()\n",
    "accuracy = correct_predictions / 40.0 * 100.0\n",
    "print(\"\\nEnhanced rule-based classifier accuracy on first 40 labeled images: \"\n",
    "      f\"{accuracy:.2f}%\\n\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(df_eval['true_label'], df_eval['auto_label'], \n",
    "                         labels=['clean', 'dirty', 'uncertain']))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(df_eval['true_label'], df_eval['auto_label'], \n",
    "                            labels=['clean', 'dirty']))\n",
    "\n",
    "# Optionally, save the updated data with the new labels.\n",
    "df.to_csv(\"features_with_enhanced_pattern_labels.csv\", index=False)\n",
    "print(\"\\nEnhanced classification complete. Results saved in 'features_with_enhanced_pattern_labels.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c032e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0837e5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
